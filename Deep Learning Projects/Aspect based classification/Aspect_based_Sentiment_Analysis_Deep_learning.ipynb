{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aspect_based_Sentiment_Analysis_Deep_learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ibH1GG7QQqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOFT2HzLQs0G",
        "colab_type": "code",
        "outputId": "eab83da0-8896-471a-d0b0-147bb34039dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "data = pd.read_csv('Data_for_preprocessing.csv')\n",
        "data.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_text</th>\n",
              "      <th>aspects</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CaliBamboo is a premium bamboo flooring produc...</td>\n",
              "      <td>flooring:neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How can that happen? It happened because quart...</td>\n",
              "      <td>countertop:negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         review_text              aspects\n",
              "0  CaliBamboo is a premium bamboo flooring produc...     flooring:neutral\n",
              "1  How can that happen? It happened because quart...  countertop:negative"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO5se4nPQ0Q0",
        "colab_type": "code",
        "outputId": "1d78950f-201b-48dc-8ab2-5a87b235c722",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "data[['aspect1','aspect2','aspect3','aspect4','aspect5']] = data.aspects.str.split(';',expand = True)\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_text</th>\n",
              "      <th>aspects</th>\n",
              "      <th>aspect1</th>\n",
              "      <th>aspect2</th>\n",
              "      <th>aspect3</th>\n",
              "      <th>aspect4</th>\n",
              "      <th>aspect5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CaliBamboo is a premium bamboo flooring produc...</td>\n",
              "      <td>flooring:neutral</td>\n",
              "      <td>flooring:neutral</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How can that happen? It happened because quart...</td>\n",
              "      <td>countertop:negative</td>\n",
              "      <td>countertop:negative</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I love this and did something like it in my ho...</td>\n",
              "      <td>space_usage:positive</td>\n",
              "      <td>space_usage:positive</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I think it will work. I painted my small bedro...</td>\n",
              "      <td>color:positive; space:positive</td>\n",
              "      <td>color:positive</td>\n",
              "      <td>space:positive</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I think you need to change the kick plate to b...</td>\n",
              "      <td>molding:positive; doors:negative</td>\n",
              "      <td>molding:positive</td>\n",
              "      <td>doors:negative</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         review_text  ... aspect5\n",
              "0  CaliBamboo is a premium bamboo flooring produc...  ...    None\n",
              "1  How can that happen? It happened because quart...  ...    None\n",
              "2  I love this and did something like it in my ho...  ...    None\n",
              "3  I think it will work. I painted my small bedro...  ...    None\n",
              "4  I think you need to change the kick plate to b...  ...    None\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIzAWGhMR205",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[['aspect11','sentiment1']] = data.aspect1.str.split(':',expand=True)\n",
        "data[['aspect21','sentiment2']] = data.aspect2.str.split(':',expand=True)\n",
        "data[['aspect31','sentiment3']] = data.aspect3.str.split(':',expand=True)\n",
        "data[['aspect41','sentiment4']] = data.aspect4.str.split(':',expand=True)\n",
        "data[['aspect51','sentiment5']] = data.aspect5.str.split(':',expand=True)\n",
        "data.drop(['aspect1','aspect2','aspect3','aspect4','aspect5'],axis = 1,inplace=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TcJGqOyrM4x",
        "colab_type": "code",
        "outputId": "f96eaed0-0008-4b38-8ff4-4b6741307097",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "data.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_text</th>\n",
              "      <th>aspects</th>\n",
              "      <th>aspect11</th>\n",
              "      <th>sentiment1</th>\n",
              "      <th>aspect21</th>\n",
              "      <th>sentiment2</th>\n",
              "      <th>aspect31</th>\n",
              "      <th>sentiment3</th>\n",
              "      <th>aspect41</th>\n",
              "      <th>sentiment4</th>\n",
              "      <th>aspect51</th>\n",
              "      <th>sentiment5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CaliBamboo is a premium bamboo flooring produc...</td>\n",
              "      <td>flooring:neutral</td>\n",
              "      <td>flooring</td>\n",
              "      <td>neutral</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How can that happen? It happened because quart...</td>\n",
              "      <td>countertop:negative</td>\n",
              "      <td>countertop</td>\n",
              "      <td>negative</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         review_text  ... sentiment5\n",
              "0  CaliBamboo is a premium bamboo flooring produc...  ...       None\n",
              "1  How can that happen? It happened because quart...  ...       None\n",
              "\n",
              "[2 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWq6sqIcRPEU",
        "colab_type": "code",
        "outputId": "07bfbe87-21aa-48fb-973d-e8abe74f13c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "nltk.download('stopwords')\n",
        "\n",
        "#Spacy\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "# Other\n",
        "import re\n",
        "import json\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#Keras\n",
        "from keras.models import load_model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uF-gHCq5TjUQ",
        "colab_type": "code",
        "outputId": "f77fc73e-60ec-48cd-bd05-cea97c7d8f4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "absa_model = Sequential()\n",
        "absa_model.add(Dense(512, input_shape=(100,), activation='relu'))\n",
        "absa_model.add((Dense(256, activation='relu')))\n",
        "absa_model.add((Dense(128, activation='relu')))\n",
        "absa_model.add(Dense(78, activation='softmax'))\n",
        "#compile model\n",
        "absa_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-5Zvo2RUEV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "vocab_size = 100 # We set a maximum size for the vocabulary\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(data.review_text)\n",
        "reviews_tokenized = pd.DataFrame(tokenizer.texts_to_matrix(data.review_text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZF7bvltbtq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder1 = LabelEncoder()\n",
        "integer_category = label_encoder1.fit_transform(data.aspect11)\n",
        "encoded_y = to_categorical(integer_category)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ngr8CEl4hCAK",
        "colab_type": "code",
        "outputId": "5f51e712-e7ec-48b4-8870-68df83e25a2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#fit aspect classifier\n",
        "absa_model.fit(reviews_tokenized,encoded_y, epochs=100, verbose=1,batch_size=100)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "Epoch 1/100\n",
            "465/465 [==============================] - 3s 7ms/step - loss: 4.2785 - acc: 0.0731\n",
            "Epoch 2/100\n",
            "465/465 [==============================] - 0s 86us/step - loss: 3.9465 - acc: 0.1097\n",
            "Epoch 3/100\n",
            "465/465 [==============================] - 0s 66us/step - loss: 3.6244 - acc: 0.1183\n",
            "Epoch 4/100\n",
            "465/465 [==============================] - 0s 65us/step - loss: 3.4418 - acc: 0.2086\n",
            "Epoch 5/100\n",
            "465/465 [==============================] - 0s 69us/step - loss: 3.2730 - acc: 0.2495\n",
            "Epoch 6/100\n",
            "465/465 [==============================] - 0s 65us/step - loss: 3.1031 - acc: 0.2688\n",
            "Epoch 7/100\n",
            "465/465 [==============================] - 0s 70us/step - loss: 2.9311 - acc: 0.3204\n",
            "Epoch 8/100\n",
            "465/465 [==============================] - 0s 64us/step - loss: 2.7452 - acc: 0.3699\n",
            "Epoch 9/100\n",
            "465/465 [==============================] - 0s 69us/step - loss: 2.5744 - acc: 0.3957\n",
            "Epoch 10/100\n",
            "465/465 [==============================] - 0s 69us/step - loss: 2.3869 - acc: 0.4344\n",
            "Epoch 11/100\n",
            "465/465 [==============================] - 0s 77us/step - loss: 2.2078 - acc: 0.4860\n",
            "Epoch 12/100\n",
            "465/465 [==============================] - 0s 75us/step - loss: 2.0240 - acc: 0.5118\n",
            "Epoch 13/100\n",
            "465/465 [==============================] - 0s 73us/step - loss: 1.8438 - acc: 0.5978\n",
            "Epoch 14/100\n",
            "465/465 [==============================] - 0s 67us/step - loss: 1.6636 - acc: 0.6280\n",
            "Epoch 15/100\n",
            "465/465 [==============================] - 0s 69us/step - loss: 1.4904 - acc: 0.6667\n",
            "Epoch 16/100\n",
            "465/465 [==============================] - 0s 80us/step - loss: 1.3202 - acc: 0.7204\n",
            "Epoch 17/100\n",
            "465/465 [==============================] - 0s 74us/step - loss: 1.1555 - acc: 0.7548\n",
            "Epoch 18/100\n",
            "465/465 [==============================] - 0s 61us/step - loss: 1.0004 - acc: 0.8065\n",
            "Epoch 19/100\n",
            "465/465 [==============================] - 0s 61us/step - loss: 0.8488 - acc: 0.8452\n",
            "Epoch 20/100\n",
            "465/465 [==============================] - 0s 64us/step - loss: 0.7176 - acc: 0.8796\n",
            "Epoch 21/100\n",
            "465/465 [==============================] - 0s 66us/step - loss: 0.5965 - acc: 0.8946\n",
            "Epoch 22/100\n",
            "465/465 [==============================] - 0s 68us/step - loss: 0.4861 - acc: 0.9269\n",
            "Epoch 23/100\n",
            "465/465 [==============================] - 0s 70us/step - loss: 0.3874 - acc: 0.9699\n",
            "Epoch 24/100\n",
            "465/465 [==============================] - 0s 69us/step - loss: 0.3086 - acc: 0.9677\n",
            "Epoch 25/100\n",
            "465/465 [==============================] - 0s 65us/step - loss: 0.2449 - acc: 0.9871\n",
            "Epoch 26/100\n",
            "465/465 [==============================] - 0s 69us/step - loss: 0.1957 - acc: 0.9871\n",
            "Epoch 27/100\n",
            "465/465 [==============================] - 0s 67us/step - loss: 0.1582 - acc: 0.9935\n",
            "Epoch 28/100\n",
            "465/465 [==============================] - 0s 65us/step - loss: 0.1263 - acc: 0.9978\n",
            "Epoch 29/100\n",
            "465/465 [==============================] - 0s 71us/step - loss: 0.1021 - acc: 0.9978\n",
            "Epoch 30/100\n",
            "465/465 [==============================] - 0s 70us/step - loss: 0.0832 - acc: 0.9978\n",
            "Epoch 31/100\n",
            "465/465 [==============================] - 0s 66us/step - loss: 0.0693 - acc: 1.0000\n",
            "Epoch 32/100\n",
            "465/465 [==============================] - 0s 81us/step - loss: 0.0600 - acc: 1.0000\n",
            "Epoch 33/100\n",
            "465/465 [==============================] - 0s 87us/step - loss: 0.0512 - acc: 1.0000\n",
            "Epoch 34/100\n",
            "465/465 [==============================] - 0s 63us/step - loss: 0.0438 - acc: 1.0000\n",
            "Epoch 35/100\n",
            "465/465 [==============================] - 0s 73us/step - loss: 0.0391 - acc: 1.0000\n",
            "Epoch 36/100\n",
            "465/465 [==============================] - 0s 71us/step - loss: 0.0343 - acc: 1.0000\n",
            "Epoch 37/100\n",
            "465/465 [==============================] - 0s 67us/step - loss: 0.0309 - acc: 1.0000\n",
            "Epoch 38/100\n",
            "465/465 [==============================] - 0s 66us/step - loss: 0.0280 - acc: 1.0000\n",
            "Epoch 39/100\n",
            "465/465 [==============================] - 0s 61us/step - loss: 0.0254 - acc: 1.0000\n",
            "Epoch 40/100\n",
            "465/465 [==============================] - 0s 65us/step - loss: 0.0233 - acc: 1.0000\n",
            "Epoch 41/100\n",
            "465/465 [==============================] - 0s 68us/step - loss: 0.0215 - acc: 1.0000\n",
            "Epoch 42/100\n",
            "465/465 [==============================] - 0s 65us/step - loss: 0.0198 - acc: 1.0000\n",
            "Epoch 43/100\n",
            "465/465 [==============================] - 0s 62us/step - loss: 0.0184 - acc: 1.0000\n",
            "Epoch 44/100\n",
            "465/465 [==============================] - 0s 63us/step - loss: 0.0173 - acc: 1.0000\n",
            "Epoch 45/100\n",
            "465/465 [==============================] - 0s 62us/step - loss: 0.0161 - acc: 1.0000\n",
            "Epoch 46/100\n",
            "465/465 [==============================] - 0s 68us/step - loss: 0.0152 - acc: 1.0000\n",
            "Epoch 47/100\n",
            "465/465 [==============================] - 0s 71us/step - loss: 0.0142 - acc: 1.0000\n",
            "Epoch 48/100\n",
            "465/465 [==============================] - 0s 63us/step - loss: 0.0134 - acc: 1.0000\n",
            "Epoch 49/100\n",
            "465/465 [==============================] - 0s 74us/step - loss: 0.0126 - acc: 1.0000\n",
            "Epoch 50/100\n",
            "465/465 [==============================] - 0s 94us/step - loss: 0.0120 - acc: 1.0000\n",
            "Epoch 51/100\n",
            "465/465 [==============================] - 0s 62us/step - loss: 0.0114 - acc: 1.0000\n",
            "Epoch 52/100\n",
            "465/465 [==============================] - 0s 63us/step - loss: 0.0108 - acc: 1.0000\n",
            "Epoch 53/100\n",
            "465/465 [==============================] - 0s 67us/step - loss: 0.0103 - acc: 1.0000\n",
            "Epoch 54/100\n",
            "465/465 [==============================] - 0s 64us/step - loss: 0.0098 - acc: 1.0000\n",
            "Epoch 55/100\n",
            "465/465 [==============================] - 0s 63us/step - loss: 0.0094 - acc: 1.0000\n",
            "Epoch 56/100\n",
            "465/465 [==============================] - 0s 69us/step - loss: 0.0090 - acc: 1.0000\n",
            "Epoch 57/100\n",
            "465/465 [==============================] - 0s 62us/step - loss: 0.0086 - acc: 1.0000\n",
            "Epoch 58/100\n",
            "465/465 [==============================] - 0s 60us/step - loss: 0.0082 - acc: 1.0000\n",
            "Epoch 59/100\n",
            "465/465 [==============================] - 0s 61us/step - loss: 0.0079 - acc: 1.0000\n",
            "Epoch 60/100\n",
            "465/465 [==============================] - 0s 62us/step - loss: 0.0075 - acc: 1.0000\n",
            "Epoch 61/100\n",
            "465/465 [==============================] - 0s 70us/step - loss: 0.0073 - acc: 1.0000\n",
            "Epoch 62/100\n",
            "465/465 [==============================] - 0s 80us/step - loss: 0.0070 - acc: 1.0000\n",
            "Epoch 63/100\n",
            "465/465 [==============================] - 0s 84us/step - loss: 0.0067 - acc: 1.0000\n",
            "Epoch 64/100\n",
            "465/465 [==============================] - 0s 75us/step - loss: 0.0065 - acc: 1.0000\n",
            "Epoch 65/100\n",
            "465/465 [==============================] - 0s 62us/step - loss: 0.0063 - acc: 1.0000\n",
            "Epoch 66/100\n",
            "465/465 [==============================] - 0s 65us/step - loss: 0.0060 - acc: 1.0000\n",
            "Epoch 67/100\n",
            "465/465 [==============================] - 0s 62us/step - loss: 0.0058 - acc: 1.0000\n",
            "Epoch 68/100\n",
            "465/465 [==============================] - 0s 67us/step - loss: 0.0056 - acc: 1.0000\n",
            "Epoch 69/100\n",
            "465/465 [==============================] - 0s 62us/step - loss: 0.0054 - acc: 1.0000\n",
            "Epoch 70/100\n",
            "465/465 [==============================] - 0s 70us/step - loss: 0.0052 - acc: 1.0000\n",
            "Epoch 71/100\n",
            "465/465 [==============================] - 0s 61us/step - loss: 0.0051 - acc: 1.0000\n",
            "Epoch 72/100\n",
            "465/465 [==============================] - 0s 61us/step - loss: 0.0049 - acc: 1.0000\n",
            "Epoch 73/100\n",
            "465/465 [==============================] - 0s 59us/step - loss: 0.0047 - acc: 1.0000\n",
            "Epoch 74/100\n",
            "465/465 [==============================] - 0s 58us/step - loss: 0.0046 - acc: 1.0000\n",
            "Epoch 75/100\n",
            "465/465 [==============================] - 0s 80us/step - loss: 0.0045 - acc: 1.0000\n",
            "Epoch 76/100\n",
            "465/465 [==============================] - 0s 62us/step - loss: 0.0043 - acc: 1.0000\n",
            "Epoch 77/100\n",
            "465/465 [==============================] - 0s 62us/step - loss: 0.0042 - acc: 1.0000\n",
            "Epoch 78/100\n",
            "465/465 [==============================] - 0s 59us/step - loss: 0.0041 - acc: 1.0000\n",
            "Epoch 79/100\n",
            "465/465 [==============================] - 0s 65us/step - loss: 0.0040 - acc: 1.0000\n",
            "Epoch 80/100\n",
            "465/465 [==============================] - 0s 64us/step - loss: 0.0038 - acc: 1.0000\n",
            "Epoch 81/100\n",
            "465/465 [==============================] - 0s 62us/step - loss: 0.0037 - acc: 1.0000\n",
            "Epoch 82/100\n",
            "465/465 [==============================] - 0s 64us/step - loss: 0.0036 - acc: 1.0000\n",
            "Epoch 83/100\n",
            "465/465 [==============================] - 0s 61us/step - loss: 0.0035 - acc: 1.0000\n",
            "Epoch 84/100\n",
            "465/465 [==============================] - 0s 60us/step - loss: 0.0034 - acc: 1.0000\n",
            "Epoch 85/100\n",
            "465/465 [==============================] - 0s 62us/step - loss: 0.0034 - acc: 1.0000\n",
            "Epoch 86/100\n",
            "465/465 [==============================] - 0s 61us/step - loss: 0.0033 - acc: 1.0000\n",
            "Epoch 87/100\n",
            "465/465 [==============================] - 0s 59us/step - loss: 0.0032 - acc: 1.0000\n",
            "Epoch 88/100\n",
            "465/465 [==============================] - 0s 63us/step - loss: 0.0031 - acc: 1.0000\n",
            "Epoch 89/100\n",
            "465/465 [==============================] - 0s 63us/step - loss: 0.0030 - acc: 1.0000\n",
            "Epoch 90/100\n",
            "465/465 [==============================] - 0s 70us/step - loss: 0.0029 - acc: 1.0000\n",
            "Epoch 91/100\n",
            "465/465 [==============================] - 0s 65us/step - loss: 0.0029 - acc: 1.0000\n",
            "Epoch 92/100\n",
            "465/465 [==============================] - 0s 55us/step - loss: 0.0028 - acc: 1.0000\n",
            "Epoch 93/100\n",
            "465/465 [==============================] - 0s 79us/step - loss: 0.0027 - acc: 1.0000\n",
            "Epoch 94/100\n",
            "465/465 [==============================] - 0s 71us/step - loss: 0.0027 - acc: 1.0000\n",
            "Epoch 95/100\n",
            "465/465 [==============================] - 0s 67us/step - loss: 0.0026 - acc: 1.0000\n",
            "Epoch 96/100\n",
            "465/465 [==============================] - 0s 88us/step - loss: 0.0025 - acc: 1.0000\n",
            "Epoch 97/100\n",
            "465/465 [==============================] - 0s 66us/step - loss: 0.0025 - acc: 1.0000\n",
            "Epoch 98/100\n",
            "465/465 [==============================] - 0s 63us/step - loss: 0.0024 - acc: 1.0000\n",
            "Epoch 99/100\n",
            "465/465 [==============================] - 0s 70us/step - loss: 0.0024 - acc: 1.0000\n",
            "Epoch 100/100\n",
            "465/465 [==============================] - 0s 72us/step - loss: 0.0023 - acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9abe4862b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STi4xv0keCr2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For Sentiment \n",
        "data.sentiment1.replace('negarive','negative',inplace=True)\n",
        "data.sentiment1.replace(' neutral','neutral',inplace=True)\n",
        "data.sentiment1.replace('negative\\n','negative',inplace=True)\n",
        "data.sentiment1.replace('positive\\n','positive',inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SE9pI3ITevOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model architecture\n",
        "sentiment_model = Sequential()\n",
        "sentiment_model.add(Dense(512, input_shape=(100,), activation='relu'))\n",
        "sentiment_model.add((Dense(256, activation='relu')))\n",
        "sentiment_model.add((Dense(128, activation='relu')))\n",
        "sentiment_model.add(Dense(3, activation='softmax'))\n",
        "#compile model\n",
        "sentiment_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "\n",
        "#encode the label variable\n",
        "label_encoder = LabelEncoder()\n",
        "integer_sentiment = label_encoder.fit_transform(data.sentiment1)\n",
        "encoded_y = to_categorical(integer_sentiment)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzZIsApYfabb",
        "colab_type": "code",
        "outputId": "028a2fa9-4ff7-4a33-e201-92369ea7de76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# #fit sentiment classifier\n",
        "sentiment_model.fit(reviews_tokenized, encoded_y ,epochs=100, verbose=1,batch_size=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "465/465 [==============================] - 0s 704us/step - loss: 0.9556 - acc: 0.5054\n",
            "Epoch 2/100\n",
            "465/465 [==============================] - 0s 69us/step - loss: 0.8481 - acc: 0.7054\n",
            "Epoch 3/100\n",
            "465/465 [==============================] - 0s 61us/step - loss: 0.7336 - acc: 0.7656\n",
            "Epoch 4/100\n",
            "465/465 [==============================] - 0s 69us/step - loss: 0.6333 - acc: 0.7828\n",
            "Epoch 5/100\n",
            "465/465 [==============================] - 0s 63us/step - loss: 0.5319 - acc: 0.8086\n",
            "Epoch 6/100\n",
            "465/465 [==============================] - 0s 64us/step - loss: 0.4425 - acc: 0.8323\n",
            "Epoch 7/100\n",
            "465/465 [==============================] - 0s 63us/step - loss: 0.3630 - acc: 0.8473\n",
            "Epoch 8/100\n",
            "465/465 [==============================] - 0s 61us/step - loss: 0.2817 - acc: 0.8946\n",
            "Epoch 9/100\n",
            "465/465 [==============================] - 0s 69us/step - loss: 0.2117 - acc: 0.9333\n",
            "Epoch 10/100\n",
            "465/465 [==============================] - 0s 80us/step - loss: 0.1517 - acc: 0.9570\n",
            "Epoch 11/100\n",
            "465/465 [==============================] - 0s 69us/step - loss: 0.0951 - acc: 0.9871\n",
            "Epoch 12/100\n",
            "465/465 [==============================] - 0s 66us/step - loss: 0.0649 - acc: 0.9957\n",
            "Epoch 13/100\n",
            "465/465 [==============================] - 0s 72us/step - loss: 0.0457 - acc: 1.0000\n",
            "Epoch 14/100\n",
            "465/465 [==============================] - 0s 63us/step - loss: 0.0274 - acc: 1.0000\n",
            "Epoch 15/100\n",
            "465/465 [==============================] - 0s 58us/step - loss: 0.0161 - acc: 1.0000\n",
            "Epoch 16/100\n",
            "465/465 [==============================] - 0s 68us/step - loss: 0.0083 - acc: 1.0000\n",
            "Epoch 17/100\n",
            "465/465 [==============================] - 0s 75us/step - loss: 0.0067 - acc: 1.0000\n",
            "Epoch 18/100\n",
            "465/465 [==============================] - 0s 70us/step - loss: 0.0040 - acc: 1.0000\n",
            "Epoch 19/100\n",
            "465/465 [==============================] - 0s 73us/step - loss: 0.0033 - acc: 1.0000\n",
            "Epoch 20/100\n",
            "465/465 [==============================] - 0s 61us/step - loss: 0.0024 - acc: 1.0000\n",
            "Epoch 21/100\n",
            "465/465 [==============================] - 0s 69us/step - loss: 0.0020 - acc: 1.0000\n",
            "Epoch 22/100\n",
            "465/465 [==============================] - 0s 61us/step - loss: 0.0017 - acc: 1.0000\n",
            "Epoch 23/100\n",
            "465/465 [==============================] - 0s 71us/step - loss: 0.0014 - acc: 1.0000\n",
            "Epoch 24/100\n",
            "465/465 [==============================] - 0s 79us/step - loss: 0.0013 - acc: 1.0000\n",
            "Epoch 25/100\n",
            "465/465 [==============================] - 0s 65us/step - loss: 0.0011 - acc: 1.0000\n",
            "Epoch 26/100\n",
            "465/465 [==============================] - 0s 78us/step - loss: 0.0010 - acc: 1.0000\n",
            "Epoch 27/100\n",
            "465/465 [==============================] - 0s 75us/step - loss: 9.5132e-04 - acc: 1.0000\n",
            "Epoch 28/100\n",
            "465/465 [==============================] - 0s 76us/step - loss: 8.7552e-04 - acc: 1.0000\n",
            "Epoch 29/100\n",
            "465/465 [==============================] - 0s 68us/step - loss: 8.1145e-04 - acc: 1.0000\n",
            "Epoch 30/100\n",
            "465/465 [==============================] - 0s 70us/step - loss: 7.5349e-04 - acc: 1.0000\n",
            "Epoch 31/100\n",
            "465/465 [==============================] - 0s 69us/step - loss: 7.0393e-04 - acc: 1.0000\n",
            "Epoch 32/100\n",
            "465/465 [==============================] - 0s 70us/step - loss: 6.6178e-04 - acc: 1.0000\n",
            "Epoch 33/100\n",
            "465/465 [==============================] - 0s 68us/step - loss: 6.2045e-04 - acc: 1.0000\n",
            "Epoch 34/100\n",
            "465/465 [==============================] - 0s 66us/step - loss: 5.8789e-04 - acc: 1.0000\n",
            "Epoch 35/100\n",
            "465/465 [==============================] - 0s 76us/step - loss: 5.5481e-04 - acc: 1.0000\n",
            "Epoch 36/100\n",
            "465/465 [==============================] - 0s 74us/step - loss: 5.2164e-04 - acc: 1.0000\n",
            "Epoch 37/100\n",
            "465/465 [==============================] - 0s 68us/step - loss: 4.9685e-04 - acc: 1.0000\n",
            "Epoch 38/100\n",
            "465/465 [==============================] - 0s 65us/step - loss: 4.7020e-04 - acc: 1.0000\n",
            "Epoch 39/100\n",
            "465/465 [==============================] - 0s 61us/step - loss: 4.4812e-04 - acc: 1.0000\n",
            "Epoch 40/100\n",
            "465/465 [==============================] - 0s 76us/step - loss: 4.2531e-04 - acc: 1.0000\n",
            "Epoch 41/100\n",
            "465/465 [==============================] - 0s 65us/step - loss: 4.0589e-04 - acc: 1.0000\n",
            "Epoch 42/100\n",
            "465/465 [==============================] - 0s 66us/step - loss: 3.8805e-04 - acc: 1.0000\n",
            "Epoch 43/100\n",
            "465/465 [==============================] - 0s 67us/step - loss: 3.7037e-04 - acc: 1.0000\n",
            "Epoch 44/100\n",
            "465/465 [==============================] - 0s 76us/step - loss: 3.5461e-04 - acc: 1.0000\n",
            "Epoch 45/100\n",
            "465/465 [==============================] - 0s 64us/step - loss: 3.3882e-04 - acc: 1.0000\n",
            "Epoch 46/100\n",
            "465/465 [==============================] - 0s 68us/step - loss: 3.2534e-04 - acc: 1.0000\n",
            "Epoch 47/100\n",
            "465/465 [==============================] - 0s 66us/step - loss: 3.1230e-04 - acc: 1.0000\n",
            "Epoch 48/100\n",
            "465/465 [==============================] - 0s 69us/step - loss: 2.9959e-04 - acc: 1.0000\n",
            "Epoch 49/100\n",
            "465/465 [==============================] - 0s 87us/step - loss: 2.8811e-04 - acc: 1.0000\n",
            "Epoch 50/100\n",
            "465/465 [==============================] - 0s 71us/step - loss: 2.7703e-04 - acc: 1.0000\n",
            "Epoch 51/100\n",
            "465/465 [==============================] - 0s 75us/step - loss: 2.6690e-04 - acc: 1.0000\n",
            "Epoch 52/100\n",
            "465/465 [==============================] - 0s 79us/step - loss: 2.5721e-04 - acc: 1.0000\n",
            "Epoch 53/100\n",
            "465/465 [==============================] - 0s 67us/step - loss: 2.4778e-04 - acc: 1.0000\n",
            "Epoch 54/100\n",
            "465/465 [==============================] - 0s 68us/step - loss: 2.3910e-04 - acc: 1.0000\n",
            "Epoch 55/100\n",
            "465/465 [==============================] - 0s 68us/step - loss: 2.3089e-04 - acc: 1.0000\n",
            "Epoch 56/100\n",
            "465/465 [==============================] - 0s 67us/step - loss: 2.2301e-04 - acc: 1.0000\n",
            "Epoch 57/100\n",
            "465/465 [==============================] - 0s 64us/step - loss: 2.1545e-04 - acc: 1.0000\n",
            "Epoch 58/100\n",
            "465/465 [==============================] - 0s 63us/step - loss: 2.0841e-04 - acc: 1.0000\n",
            "Epoch 59/100\n",
            "465/465 [==============================] - 0s 67us/step - loss: 2.0192e-04 - acc: 1.0000\n",
            "Epoch 60/100\n",
            "465/465 [==============================] - 0s 70us/step - loss: 1.9502e-04 - acc: 1.0000\n",
            "Epoch 61/100\n",
            "465/465 [==============================] - 0s 72us/step - loss: 1.8874e-04 - acc: 1.0000\n",
            "Epoch 62/100\n",
            "465/465 [==============================] - 0s 70us/step - loss: 1.8252e-04 - acc: 1.0000\n",
            "Epoch 63/100\n",
            "465/465 [==============================] - 0s 66us/step - loss: 1.7739e-04 - acc: 1.0000\n",
            "Epoch 64/100\n",
            "465/465 [==============================] - 0s 76us/step - loss: 1.7170e-04 - acc: 1.0000\n",
            "Epoch 65/100\n",
            "465/465 [==============================] - 0s 67us/step - loss: 1.6683e-04 - acc: 1.0000\n",
            "Epoch 66/100\n",
            "465/465 [==============================] - 0s 69us/step - loss: 1.6179e-04 - acc: 1.0000\n",
            "Epoch 67/100\n",
            "465/465 [==============================] - 0s 73us/step - loss: 1.5707e-04 - acc: 1.0000\n",
            "Epoch 68/100\n",
            "465/465 [==============================] - 0s 79us/step - loss: 1.5261e-04 - acc: 1.0000\n",
            "Epoch 69/100\n",
            "465/465 [==============================] - 0s 81us/step - loss: 1.4829e-04 - acc: 1.0000\n",
            "Epoch 70/100\n",
            "465/465 [==============================] - 0s 94us/step - loss: 1.4443e-04 - acc: 1.0000\n",
            "Epoch 71/100\n",
            "465/465 [==============================] - 0s 84us/step - loss: 1.4029e-04 - acc: 1.0000\n",
            "Epoch 72/100\n",
            "465/465 [==============================] - 0s 86us/step - loss: 1.3655e-04 - acc: 1.0000\n",
            "Epoch 73/100\n",
            "465/465 [==============================] - 0s 80us/step - loss: 1.3282e-04 - acc: 1.0000\n",
            "Epoch 74/100\n",
            "465/465 [==============================] - 0s 85us/step - loss: 1.2937e-04 - acc: 1.0000\n",
            "Epoch 75/100\n",
            "465/465 [==============================] - 0s 77us/step - loss: 1.2596e-04 - acc: 1.0000\n",
            "Epoch 76/100\n",
            "465/465 [==============================] - 0s 81us/step - loss: 1.2290e-04 - acc: 1.0000\n",
            "Epoch 77/100\n",
            "465/465 [==============================] - 0s 77us/step - loss: 1.1972e-04 - acc: 1.0000\n",
            "Epoch 78/100\n",
            "465/465 [==============================] - 0s 82us/step - loss: 1.1667e-04 - acc: 1.0000\n",
            "Epoch 79/100\n",
            "465/465 [==============================] - 0s 83us/step - loss: 1.1387e-04 - acc: 1.0000\n",
            "Epoch 80/100\n",
            "465/465 [==============================] - 0s 82us/step - loss: 1.1113e-04 - acc: 1.0000\n",
            "Epoch 81/100\n",
            "465/465 [==============================] - 0s 79us/step - loss: 1.0830e-04 - acc: 1.0000\n",
            "Epoch 82/100\n",
            "465/465 [==============================] - 0s 75us/step - loss: 1.0572e-04 - acc: 1.0000\n",
            "Epoch 83/100\n",
            "465/465 [==============================] - 0s 75us/step - loss: 1.0323e-04 - acc: 1.0000\n",
            "Epoch 84/100\n",
            "465/465 [==============================] - 0s 69us/step - loss: 1.0077e-04 - acc: 1.0000\n",
            "Epoch 85/100\n",
            "465/465 [==============================] - 0s 64us/step - loss: 9.8520e-05 - acc: 1.0000\n",
            "Epoch 86/100\n",
            "465/465 [==============================] - 0s 65us/step - loss: 9.6162e-05 - acc: 1.0000\n",
            "Epoch 87/100\n",
            "465/465 [==============================] - 0s 83us/step - loss: 9.4069e-05 - acc: 1.0000\n",
            "Epoch 88/100\n",
            "465/465 [==============================] - 0s 74us/step - loss: 9.1869e-05 - acc: 1.0000\n",
            "Epoch 89/100\n",
            "465/465 [==============================] - 0s 80us/step - loss: 8.9885e-05 - acc: 1.0000\n",
            "Epoch 90/100\n",
            "465/465 [==============================] - 0s 65us/step - loss: 8.7811e-05 - acc: 1.0000\n",
            "Epoch 91/100\n",
            "465/465 [==============================] - 0s 62us/step - loss: 8.5873e-05 - acc: 1.0000\n",
            "Epoch 92/100\n",
            "465/465 [==============================] - 0s 62us/step - loss: 8.4064e-05 - acc: 1.0000\n",
            "Epoch 93/100\n",
            "465/465 [==============================] - 0s 82us/step - loss: 8.2292e-05 - acc: 1.0000\n",
            "Epoch 94/100\n",
            "465/465 [==============================] - 0s 62us/step - loss: 8.0491e-05 - acc: 1.0000\n",
            "Epoch 95/100\n",
            "465/465 [==============================] - 0s 75us/step - loss: 7.8886e-05 - acc: 1.0000\n",
            "Epoch 96/100\n",
            "465/465 [==============================] - 0s 65us/step - loss: 7.7297e-05 - acc: 1.0000\n",
            "Epoch 97/100\n",
            "465/465 [==============================] - 0s 70us/step - loss: 7.5633e-05 - acc: 1.0000\n",
            "Epoch 98/100\n",
            "465/465 [==============================] - 0s 86us/step - loss: 7.4139e-05 - acc: 1.0000\n",
            "Epoch 99/100\n",
            "465/465 [==============================] - 0s 69us/step - loss: 7.2597e-05 - acc: 1.0000\n",
            "Epoch 100/100\n",
            "465/465 [==============================] - 0s 74us/step - loss: 7.1187e-05 - acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9abe470278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4syczAXZJXBT",
        "colab_type": "code",
        "outputId": "1ec1606e-0336-463a-f54a-f98745b7bc49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "test_reviews = [\n",
        "'Oh what a beautiful brick home you have!','The roof looks fine.  I love your door color.  Add more color plants in front of the porch.',\n",
        "'the space was not good','Design combination of triangular roof with a curved space below is beautiful!',\n",
        " 'I\\'m a fire guy as well. However, in an island, I think it\\'s going to depend on your venting. A surface-mount downdraft sucks a lot of the BTUs from a gas flameâ€”that\\'s what we had it in our last house. With proper overhead venting, that\\'s not a concern.'\n",
        "]\n",
        "# Aspect preprocessing\n",
        "test_reviews = [review.lower() for review in test_reviews]\n",
        "test_aspect_terms = []\n",
        "for review in nlp.pipe(test_reviews):\n",
        "    chunks = [(chunk.root.text) for chunk in review.noun_chunks if chunk.root.pos_ == 'NOUN']\n",
        "    test_aspect_terms.append(' '.join(chunks))\n",
        "print(test_aspect_terms)\n",
        "\n",
        "test_aspect_terms = pd.DataFrame(tokenizer.texts_to_matrix(test_aspect_terms))\n",
        "print(test_aspect_terms)\n",
        "\n",
        "# Sentiment preprocessing\n",
        "test_sentiment_terms = []\n",
        "for review in nlp.pipe(test_reviews):\n",
        "        if review.is_parsed:\n",
        "            test_sentiment_terms.append(' '.join([token.lemma_ for token in review if (not token.is_stop and not token.is_punct and (token.pos_ == \"ADJ\" or token.pos_ == \"VERB\"))]))\n",
        "        else:\n",
        "            test_sentiment_terms.append('') \n",
        "test_sentiment_terms = pd.DataFrame(tokenizer.texts_to_matrix(test_sentiment_terms))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['home', 'roof color plants front porch', 'space', 'combination roof space', 'guy island venting downdraft lot btus gas house venting concern']\n",
            "    0    1    2    3    4    5    6   ...   93   94   95   96   97   98   99\n",
            "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
            "\n",
            "[5 rows x 100 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_2fzuOujQ0B",
        "colab_type": "code",
        "outputId": "ae23c337-d4e3-42cf-9a04-e8514d33c963",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Models output\n",
        "test_aspect_categories =  label_encoder1.inverse_transform(absa_model.predict_classes(test_aspect_terms))\n",
        "print(test_aspect_categories)\n",
        "test_sentiment = label_encoder.inverse_transform(sentiment_model.predict_classes(test_sentiment_terms))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['design' 'color' 'design' 'design' 'windows']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KORZjkihke99",
        "colab_type": "code",
        "outputId": "c0c9eedc-a72c-48a1-84e0-dc1c512f7176",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "for i in range(len(test_sentiment)):\n",
        "    print(\"Review \" + str(i+1) + \" is expressing a  \" + test_sentiment[i] + \" : \" + test_aspect_categories[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review 1 is expressing a  positive : design\n",
            "Review 2 is expressing a  positive : color\n",
            "Review 3 is expressing a  positive : design\n",
            "Review 4 is expressing a  positive : design\n",
            "Review 5 is expressing a  negative : windows\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MLKM7vhfk5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vdl7wVeDwTcr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}